{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15101180343a400281b0e57217af8afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b28736f01d7e4768b321626f76d1c405",
              "IPY_MODEL_b4c664b66e954ec0a8d8990e782aea61",
              "IPY_MODEL_d2d8442ed68f40dd9c64074944ca4955"
            ],
            "layout": "IPY_MODEL_da04935d439a4591880f9c5709a5f689"
          }
        },
        "b28736f01d7e4768b321626f76d1c405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e330dbc5041d4d708f105b344e010c19",
            "placeholder": "​",
            "style": "IPY_MODEL_0561a51f525c489e9f7b3495667fc312",
            "value": "Map: 100%"
          }
        },
        "b4c664b66e954ec0a8d8990e782aea61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0135614684d7409b87bfbc108163b7b3",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f4faf0f85ad41e39de63170cf2dbde1",
            "value": 4358
          }
        },
        "d2d8442ed68f40dd9c64074944ca4955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_085ada9b7cd84387bb2b3f0716e11089",
            "placeholder": "​",
            "style": "IPY_MODEL_c5085da828be4d00944fede38c1eb082",
            "value": " 4358/4358 [00:04&lt;00:00, 1000.40 examples/s]"
          }
        },
        "da04935d439a4591880f9c5709a5f689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e330dbc5041d4d708f105b344e010c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0561a51f525c489e9f7b3495667fc312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0135614684d7409b87bfbc108163b7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f4faf0f85ad41e39de63170cf2dbde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "085ada9b7cd84387bb2b3f0716e11089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5085da828be4d00944fede38c1eb082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción al Pre-training de LLMs\n",
        "\n",
        "El pre-training de los modelos de lenguaje es una técnica clave que permite entrenar modelos a gran escala en corpus de texto no supervisado. Este enfoque ha revolucionado el procesamiento del lenguaje natural, ya que los modelos entrenados aprenden representaciones generales del lenguaje antes de ser ajustados (fine-tuning) para tareas específicas como clasificación de texto, traducción o respuestas automáticas.\n",
        "\n",
        "En este Colab, cubriremos los principios básicos del pre-training de LLMs, los métodos más comunes, y un ejemplo práctico de pre-entrenamiento en un conjunto de datos de texto.\n"
      ],
      "metadata": {
        "id": "kj8aMbWWWxOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Empezamos con el pre-training"
      ],
      "metadata": {
        "id": "ovLXe1LzbjZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de las bibliotecas necesarias\n",
        "!pip install -U transformers datasets --quiet"
      ],
      "metadata": {
        "id": "JS5WQ6CpXXOm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pare el pre-entrenamiento necesitamos un dataset, ya sea que el dataset sea local o importado de alguna librería es necesaria la muestra de datos para que el proceso"
      ],
      "metadata": {
        "id": "VpwGXR_MXiRW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWqPDqs4V--J",
        "outputId": "bdded31d-eb04-48c5-845c-14249c56310b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 4358\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 36718\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3760\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Cargar el dataset para pre-entrenamiento\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notemos que este dataset esta dividido en tres grupos, test, train y validation. Así que no necesitamos dividir la muestra, pero les dejamos comentado una celda abajo sobre cómo se puede dividir un dataset.\n",
        "\n",
        "Nuestra recomendación es dividir la muestra en dos grupos, un grupo para entrenar el modelo, y un segundo grupo para evaluar el desempeño del mismo. No queremos entrenar y evaluar con los mismos datos ya que eso puede generar que el modelo \"memorice\" las respuestas correctas en lugar de aprender realmente"
      ],
      "metadata": {
        "id": "uHFLb5hQaUYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "max_samples = 30000\n",
        "\n",
        "# Limitamos el tamaño del dataset si es necesario\n",
        "total_size = min(max_samples, len(dataset))\n",
        "val_size = int(total_size * 0.2)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "# División del conjunto de datos en entrenamiento y validación\n",
        "split_ds = dataset.train_test_split(\n",
        "    train_size=train_size,\n",
        "    test_size=val_size,\n",
        "    seed=42\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wTyM68EGarRW",
        "outputId": "51198027-accf-4e06-d1c8-ac26f7df6022"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmax_samples = 30000\\n\\n# Limitamos el tamaño del dataset si es necesario\\ntotal_size = min(max_samples, len(dataset))\\nval_size = int(total_size * 0.2)\\ntrain_size = total_size - val_size\\n\\n# División del conjunto de datos en entrenamiento y validación\\nsplit_ds = dataset.train_test_split(\\n    train_size=train_size,\\n    test_size=val_size,\\n    seed=42\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También requerimos de un modelo, en este caso usaremos GPT-2"
      ],
      "metadata": {
        "id": "Zmrk3CM6YI3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Definir el tokenizador y el modelo\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Asignar el token de padding como el eos_token (fin de secuencia)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "lDTqvHlmYM1L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizar las muestras del dataset, debemos pasarla por el tokenizer para que el modelo lo pueda procesar. Por lo que haremos una función que mapee las muestras en base al tokenizer"
      ],
      "metadata": {
        "id": "vpB5KQ9wYZ1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para tokenizar los datos\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Tokenizamos los conjuntos de entrenamiento y validación por separado\n",
        "tokenized_train = dataset['train'].map(tokenize_function, batched=True)\n",
        "tokenized_val = dataset['test'].map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "15101180343a400281b0e57217af8afc",
            "b28736f01d7e4768b321626f76d1c405",
            "b4c664b66e954ec0a8d8990e782aea61",
            "d2d8442ed68f40dd9c64074944ca4955",
            "da04935d439a4591880f9c5709a5f689",
            "e330dbc5041d4d708f105b344e010c19",
            "0561a51f525c489e9f7b3495667fc312",
            "0135614684d7409b87bfbc108163b7b3",
            "3f4faf0f85ad41e39de63170cf2dbde1",
            "085ada9b7cd84387bb2b3f0716e11089",
            "c5085da828be4d00944fede38c1eb082"
          ]
        },
        "id": "Lg9WNFCvYnFP",
        "outputId": "abd7edb5-4f19-48ce-ec82-f706637f903c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15101180343a400281b0e57217af8afc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora viene la parte del entramiento. Podemos importar un Trainer para configurarlo de manera sencilla. A modo de ejemplo:"
      ],
      "metadata": {
        "id": "4I2EcQ1jZbyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Configuración de los argumentos de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Definir el trainer con los datos tokenizados\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train, # Usamos el conjunto de entrenamiento para entrenar\n",
        "    eval_dataset=tokenized_val  # Usamos el conjunto de validación para evaluar\n",
        ")\n"
      ],
      "metadata": {
        "id": "2XVVzP8FZUau"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que configurarmos el training, podemos empezarlo"
      ],
      "metadata": {
        "id": "aewmzl3gZva2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "trainer.train() # Esto va a consumir toda la memoria RAM en el colab y se va a cortar\n"
      ],
      "metadata": {
        "id": "obGwtY1LZr7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El proceso de entrenamiento siempre es muy costoso, por lo que entrenarlo todo de una vez necesita buenos recursos.\n",
        "\n",
        "Sin embargo, no es el fin del mundo. Les presentamos un par de alternativas si el proceso es demasiado costoso:\n",
        "\n",
        "1. Si estás utilizando un dataset grande, puedes reducir aún más el número de muestras (max_samples) o disminuir el batch size del Trainer. Disminuir el batch_size puede ayudar significativamente a reducir el uso de memoria.\n",
        "\n",
        "2. La opción save_steps permite que el Trainer guarde el modelo periódicamente durante el entrenamiento, lo que es útil para evitar que el trabajo se pierda si se interrumpe el proceso. Puedes guardar el modelo y su estado cada ciertos pasos, como se muestra en el ejemplo anterior."
      ],
      "metadata": {
        "id": "nJkCJ1c9duKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternativa uno\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,  # Puedes disminuir el número de épocas también\n",
        "    per_device_train_batch_size=2,  # Disminuir batch size a 2\n",
        "    save_steps=1000,  # Guardar más seguido para no perder el progreso\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"steps\",  # Evaluar cada ciertos pasos\n",
        "    eval_steps=1000,  # Evaluar cada 1000 pasos\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train, # Usamos el conjunto de entrenamiento para entrenar\n",
        "    eval_dataset=tokenized_val  # Usamos el conjunto de validación para evaluar\n",
        ")"
      ],
      "metadata": {
        "id": "W76o6QkDeqXN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternativa dos\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=1000,  # Guardar el modelo cada 1000 pasos\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,  # Evaluar cada 1000 pasos\n",
        "    save_total_limit=2,  # Mantener solo los últimos 2 checkpoints\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train, # Usamos el conjunto de entrenamiento para entrenar\n",
        "    eval_dataset=tokenized_val  # Usamos el conjunto de validación para evaluar\n",
        ")"
      ],
      "metadata": {
        "id": "Z7b7L4y8e04l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elige la alternativa que prefieras y comprobemos que pasa:"
      ],
      "metadata": {
        "id": "dNEXTQ9SffjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "VMDpyvwLfi68",
        "outputId": "79749425-a39c-4543-9ffc-26942788c7c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2052\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2053\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3548\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3550\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   3551\u001b[0m                     \u001b[0;34m\"The model did not return a loss from the inputs, only the following keys: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3552\u001b[0m                     \u001b[0;34mf\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y podemos deternos luego del entramiento, guardando el modelo y el tokenizer para seguir siendo usados a futuro"
      ],
      "metadata": {
        "id": "S14OhP8baA3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo pre-entrenado\n",
        "model.save_pretrained(\"pretrained_model\")\n",
        "tokenizer.save_pretrained(\"pretrained_model\")\n"
      ],
      "metadata": {
        "id": "HewiCNv5Z_92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando queramos cargar el modelo para continuar el proceso es tan simple cómo esto"
      ],
      "metadata": {
        "id": "xaSHWCfzgiU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(resume_from_checkpoint=True)\n"
      ],
      "metadata": {
        "id": "SF21p2zbgh4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}